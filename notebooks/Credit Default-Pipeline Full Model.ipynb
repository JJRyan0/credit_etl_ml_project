{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0bed6-96fe-4538-bf06-28ffd0a766cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Libaries and dependencies\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "###=======Load Data from PostgreSQL=============##\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "db_config = {\n",
    "    \"user\": \"INSERT\",\n",
    "    \"password\": \"INSERT\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"credit_etl\"\n",
    "}\n",
    "\n",
    "engine = create_engine(f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\")\n",
    "\n",
    "#load data from PGsql DB to a DataFrame\n",
    "query = \"select * from raw.raw_customer_default_payment\"\n",
    "\n",
    "credit_data = pd.read_sql(query, engine)\n",
    "\n",
    "##=======Pipline - Credit Risk Model - XGboost Classification - Credit Best Model V1===========#\n",
    "\n",
    "#create  x and y as target variable\n",
    "x = credit_data.drop(columns= ['default_payment_next_month', 'id'])\n",
    "y = credit_data['default_payment_next_month']\n",
    "\n",
    "#train test split with test size 20%\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "#Define the numerical cols for the preprocessor activities\n",
    "numerical_cols = credit_data\n",
    "\n",
    "# Calculate the scale weight ratio for imbalanced classes\n",
    "counter = Counter(y_train) \n",
    "scale_weight_ratio = counter[0] / counter[1]\n",
    "\n",
    "#define the column transformer to scale the data using standard method\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    #('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), slice(0, x.shape[1]))\n",
    "])\n",
    "\n",
    "#Apply SMOTE to balance all classes to match the majority class.\n",
    "smote = SMOTE(random_state=42, k_neighbors=5, sampling_strategy='auto')\n",
    "\n",
    "#Kfold stratification method\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('smote',SMOTE(random_state=42)),#SMOTE to handle class imbalance\n",
    "    #('selection', SelectKBest(score_func = f_classif, k=15)),\n",
    "    ('clf', XGBClassifier(eval_metric='auc', random_state=42, scale_pos_weight=scale_weight_ratio))\n",
    "])\n",
    "\n",
    "\n",
    "# Define the scoring method for cross-validation (AUC in this case)\n",
    "scoring = make_scorer(roc_auc_score)\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [50, 100, 200, 300],\n",
    "    'clf__max_depth': [3,5],\n",
    "    'clf__learning_rate': [0.01, 0.05],\n",
    "    'clf__subsample': [0.8],\n",
    "    'clf__reg_alpha': [0, 0.3, 0.7],  # L1 regularization\n",
    "    'clf__reg_lambda': [1, 10]      # L2 regularization\n",
    "}\n",
    "\n",
    "#Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid,\n",
    "                           scoring=scoring, cv=cv, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(x_train, y_train)  # optional, suppress per-iteration output\n",
    "\n",
    "#gwt best params & scores for use in predict test probabilities \n",
    "best_params = grid_search.best_params_\n",
    "print('Best Params:', best_params)\n",
    "print(\"Best AUC:\", grid_search.best_score_)\n",
    "\n",
    "#usiing the best estimator from grid search predict on test set\n",
    "credit_best_model = grid_search.best_estimator_\n",
    "y_pred_proba = credit_best_model.predict_proba(x_test)[:,1]\n",
    "test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC on test set: {test_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
